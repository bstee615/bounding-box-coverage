{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TileName', 'geometry'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whole tiles\n",
    "tiles_df = gpd.read_file('output\\covering_tiles.json')\n",
    "tiles_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TileName</th>\n",
       "      <th>FieldCount</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>17TKE</td>\n",
       "      <td>13113</td>\n",
       "      <td>POLYGON Z ((-84.54546 40.59640 0.00000, -83.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>16TGK</td>\n",
       "      <td>12987</td>\n",
       "      <td>POLYGON Z ((-84.63579 40.62665 0.00000, -83.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>17TKF</td>\n",
       "      <td>6986</td>\n",
       "      <td>POLYGON Z ((-84.59412 41.49565 0.00000, -83.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>16TGL</td>\n",
       "      <td>6982</td>\n",
       "      <td>POLYGON Z ((-84.60330 41.52686 0.00000, -83.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>17SKD</td>\n",
       "      <td>6834</td>\n",
       "      <td>POLYGON Z ((-84.49898 39.69751 0.00000, -83.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>13SGA</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((-102.75207 37.02528 0.00000, -101....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>37VCD</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((35.64383 57.69781 0.00000, 37.4851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>30VWJ</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((-3.00034 57.74230 0.00000, -1.1565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>37VDD</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((37.32001 57.73116 0.00000, 39.1639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04QGJ</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON Z ((-157.06721 21.69215 0.00000, -156....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1183 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TileName  FieldCount                                           geometry\n",
       "491     17TKE       13113  POLYGON Z ((-84.54546 40.59640 0.00000, -83.24...\n",
       "436     16TGK       12987  POLYGON Z ((-84.63579 40.62665 0.00000, -83.33...\n",
       "492     17TKF        6986  POLYGON Z ((-84.59412 41.49565 0.00000, -83.28...\n",
       "437     16TGL        6982  POLYGON Z ((-84.60330 41.52686 0.00000, -83.28...\n",
       "455     17SKD        6834  POLYGON Z ((-84.49898 39.69751 0.00000, -83.21...\n",
       "...       ...         ...                                                ...\n",
       "114     13SGA           1  POLYGON Z ((-102.75207 37.02528 0.00000, -101....\n",
       "1028    37VCD           1  POLYGON Z ((35.64383 57.69781 0.00000, 37.4851...\n",
       "745     30VWJ           1  POLYGON Z ((-3.00034 57.74230 0.00000, -1.1565...\n",
       "1030    37VDD           1  POLYGON Z ((37.32001 57.73116 0.00000, 39.1639...\n",
       "0       04QGJ           1  POLYGON Z ((-157.06721 21.69215 0.00000, -156....\n",
       "\n",
       "[1183 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match tiles to fields\n",
    "tiles_to_fields_df = pd.read_csv('output/tiles_to_fields.csv')\n",
    "tiles_to_fields_df = tiles_to_fields_df.dropna()\n",
    "tiles_to_fields_df[\"FieldId\"] = tiles_to_fields_df[\"FieldId\"].astype('int32')\n",
    "tiles_to_fields_df[\"FieldId\"].sort_values()\n",
    "tiles_counts = tiles_to_fields_df.groupby('TileName').size()\n",
    "tiles_counts = tiles_counts.to_frame().reset_index()\n",
    "tiles_counts = tiles_counts.rename(columns={0:'FieldCount'})\n",
    "join_df = tiles_counts.merge(tiles_df)\n",
    "join_df = join_df.sort_values('FieldCount', ascending=False)\n",
    "join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing WKT...\n",
      "9997 fields\n",
      "Parsing WKT...\n",
      "9878 fields\n",
      "Parsing WKT...\n",
      "9918 fields\n",
      "Parsing WKT...\n",
      "10000 fields\n",
      "Parsing WKT...\n",
      "9939 fields\n",
      "Parsing WKT...\n",
      "9991 fields\n",
      "Parsing WKT...\n",
      "9995 fields\n",
      "Parsing WKT...\n",
      "10000 fields\n",
      "Parsing WKT...\n",
      "9999 fields\n",
      "Parsing WKT...\n",
      "9993 fields\n",
      "Parsing WKT...\n",
      "10000 fields\n",
      "Parsing WKT...\n",
      "9995 fields\n",
      "Parsing WKT...\n",
      "9998 fields\n",
      "Parsing WKT...\n",
      "10000 fields\n",
      "Parsing WKT...\n",
      "9988 fields\n",
      "Parsing WKT...\n",
      "10000 fields\n",
      "Parsing WKT...\n",
      "9999 fields\n",
      "Parsing WKT...\n",
      "9981 fields\n",
      "Parsing WKT...\n",
      "10000 fields\n",
      "Parsing WKT...\n",
      "9891 fields\n",
      "Parsing WKT...\n",
      "9408 fields\n",
      "Parsing WKT...\n",
      "42 fields\n",
      "Parsing WKT...\n",
      "0 fields\n"
     ]
    }
   ],
   "source": [
    "from reader import load_fields\n",
    "rewrite=True\n",
    "if rewrite:\n",
    "    i = 0\n",
    "    skip = 1\n",
    "    max_rows_per_chunk = 10000\n",
    "    input_file = 'input/results-all.txt'\n",
    "    while True:\n",
    "        with open(input_file, encoding='utf-16') as f:\n",
    "            column_names = f.readline().strip().split('\\t')\n",
    "        fields_df = load_fields(input_file, skip, max_rows_per_chunk, column_names)\n",
    "        if len(fields_df) == 0:\n",
    "            break\n",
    "        else:\n",
    "            fields_df.drop(columns=['geometry']).to_csv(f'tmp/split{i}-{max_rows_per_chunk}.csv', index=False, sep='\\t')\n",
    "            i += 1\n",
    "            skip += len(fields_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 auto tiles: ['17TKE', '16TGK', '17TKF', '16TGL', '17SKD', '16SGJ', '17TLF', '15TVG', '16TFL', '18TUN']\n",
      "1 tiles: ['16TFL']\n",
      "3348 fields\n",
      "3348 unique fields\n"
     ]
    }
   ],
   "source": [
    "top_k_field_counts = join_df.sort_values('FieldCount', ascending=False).head(10)\n",
    "collect_tiles = top_k_field_counts[\"TileName\"].values.tolist()\n",
    "print(len(collect_tiles), 'auto tiles:', collect_tiles)\n",
    "\n",
    "# Override with manual tiles to reduce overlapping\n",
    "# manual_collect_tiles = ['17TLF', '16TGL', '17TKE', '17SKD', '16TFL']\n",
    "manual_collect_tiles = ['16TFL']\n",
    "collect_tiles = manual_collect_tiles\n",
    "\n",
    "print(len(collect_tiles), 'tiles:', collect_tiles)\n",
    "collect_fields = tiles_to_fields_df[tiles_to_fields_df[\"TileName\"].isin(collect_tiles)]\n",
    "print(len(collect_fields), 'fields')\n",
    "unique_collect_fields = set(collect_fields[\"FieldId\"])\n",
    "print(len(unique_collect_fields), 'unique fields')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: [WindowsPath('tmp/split0-10000.csv'), WindowsPath('tmp/split1-10000.csv'), WindowsPath('tmp/split10-10000.csv'), WindowsPath('tmp/split11-10000.csv'), WindowsPath('tmp/split12-10000.csv'), WindowsPath('tmp/split13-10000.csv'), WindowsPath('tmp/split14-10000.csv'), WindowsPath('tmp/split15-10000.csv'), WindowsPath('tmp/split16-10000.csv'), WindowsPath('tmp/split17-10000.csv'), WindowsPath('tmp/split18-10000.csv'), WindowsPath('tmp/split19-10000.csv'), WindowsPath('tmp/split2-10000.csv'), WindowsPath('tmp/split20-10000.csv'), WindowsPath('tmp/split21-10000.csv'), WindowsPath('tmp/split3-10000.csv'), WindowsPath('tmp/split4-10000.csv'), WindowsPath('tmp/split5-10000.csv'), WindowsPath('tmp/split6-10000.csv'), WindowsPath('tmp/split7-10000.csv'), WindowsPath('tmp/split8-10000.csv'), WindowsPath('tmp/split9-10000.csv')]\n",
      "filter starts with 9997 rows\n",
      "filter ends with 10 rows\n",
      "Parsing WKT...\n",
      "10 fields\n",
      "10 fields in tmp\\split0-10000.csv\n",
      "filter starts with 9878 rows\n",
      "filter ends with 359 rows\n",
      "Parsing WKT...\n",
      "359 fields\n",
      "359 fields in tmp\\split1-10000.csv\n",
      "filter starts with 10000 rows\n",
      "filter ends with 281 rows\n",
      "Parsing WKT...\n",
      "281 fields\n",
      "281 fields in tmp\\split10-10000.csv\n",
      "filter starts with 9995 rows\n",
      "filter ends with 103 rows\n",
      "Parsing WKT...\n",
      "103 fields\n",
      "103 fields in tmp\\split11-10000.csv\n",
      "filter starts with 9998 rows\n",
      "filter ends with 54 rows\n",
      "Parsing WKT...\n",
      "54 fields\n",
      "54 fields in tmp\\split12-10000.csv\n",
      "filter starts with 10000 rows\n",
      "filter ends with 90 rows\n",
      "Parsing WKT...\n",
      "90 fields\n",
      "90 fields in tmp\\split13-10000.csv\n",
      "filter starts with 9988 rows\n",
      "filter ends with 73 rows\n",
      "Parsing WKT...\n",
      "73 fields\n",
      "73 fields in tmp\\split14-10000.csv\n",
      "filter starts with 10000 rows\n",
      "filter ends with 45 rows\n",
      "Parsing WKT...\n",
      "45 fields\n",
      "45 fields in tmp\\split15-10000.csv\n",
      "filter starts with 9999 rows\n",
      "filter ends with 0 rows\n",
      "Parsing WKT...\n",
      "0 fields\n",
      "0 fields in tmp\\split16-10000.csv\n",
      "filter starts with 9981 rows\n",
      "filter ends with 10 rows\n",
      "Parsing WKT...\n",
      "10 fields\n",
      "10 fields in tmp\\split17-10000.csv\n",
      "filter starts with 10000 rows\n",
      "filter ends with 114 rows\n",
      "Parsing WKT...\n",
      "114 fields\n",
      "114 fields in tmp\\split18-10000.csv\n",
      "filter starts with 9891 rows\n",
      "filter ends with 129 rows\n",
      "Parsing WKT...\n",
      "129 fields\n",
      "129 fields in tmp\\split19-10000.csv\n",
      "filter starts with 9918 rows\n",
      "filter ends with 968 rows\n",
      "Parsing WKT...\n",
      "968 fields\n",
      "968 fields in tmp\\split2-10000.csv\n",
      "filter starts with 9408 rows\n",
      "filter ends with 34 rows\n",
      "Parsing WKT...\n",
      "34 fields\n",
      "34 fields in tmp\\split20-10000.csv\n",
      "filter starts with 42 rows\n",
      "filter ends with 0 rows\n",
      "Parsing WKT...\n",
      "0 fields\n",
      "0 fields in tmp\\split21-10000.csv\n",
      "filter starts with 10000 rows\n",
      "filter ends with 51 rows\n",
      "Parsing WKT...\n",
      "51 fields\n",
      "51 fields in tmp\\split3-10000.csv\n",
      "filter starts with 9939 rows\n",
      "filter ends with 638 rows\n",
      "Parsing WKT...\n",
      "638 fields\n",
      "638 fields in tmp\\split4-10000.csv\n",
      "filter starts with 9991 rows\n",
      "filter ends with 96 rows\n",
      "Parsing WKT...\n",
      "96 fields\n",
      "96 fields in tmp\\split5-10000.csv\n",
      "filter starts with 9995 rows\n",
      "filter ends with 208 rows\n",
      "Parsing WKT...\n",
      "208 fields\n",
      "208 fields in tmp\\split6-10000.csv\n",
      "filter starts with 10000 rows\n",
      "filter ends with 23 rows\n",
      "Parsing WKT...\n",
      "23 fields\n",
      "23 fields in tmp\\split7-10000.csv\n",
      "filter starts with 9999 rows\n",
      "filter ends with 63 rows\n",
      "Parsing WKT...\n",
      "63 fields\n",
      "63 fields in tmp\\split8-10000.csv\n",
      "filter starts with 9993 rows\n",
      "filter ends with 0 rows\n",
      "Parsing WKT...\n",
      "0 fields\n",
      "0 fields in tmp\\split9-10000.csv\n",
      "3349 fields in total\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "csvs = list(sorted(Path('tmp').glob('*.csv'), key=lambda fname: str(fname)))\n",
    "print('files:', csvs)\n",
    "# csvs = csvs[:1]  # NOTE: test\n",
    "all_fields_df = None\n",
    "def filter_to_collect(df):\n",
    "    print('filter starts with', len(df), 'rows')\n",
    "    df = df[df[\"FieldId\"].isin(unique_collect_fields)]\n",
    "    print('filter ends with', len(df), 'rows')\n",
    "    return df\n",
    "for fname in csvs:\n",
    "    fields_df = load_fields(fname, 0, None, None, encoding='utf-8', filter_fn=filter_to_collect)\n",
    "    print(len(fields_df), 'fields in', fname)\n",
    "    if all_fields_df is None:\n",
    "        all_fields_df = fields_df\n",
    "    else:\n",
    "        all_fields_df = pd.concat((all_fields_df, fields_df), ignore_index=True).reset_index(drop=True)\n",
    "print(len(all_fields_df), 'fields in total')\n",
    "all_fields_df.to_file(driver = 'ESRI Shapefile', filename= \"tmp/field_polygons.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "all_fields_df.to_file(driver = 'KML', filename= \"tmp/field_polygons.kml\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d57c8628a75ca658fe9c782c596fddf085ad5477cde2e1525f795b74cf3e2991"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
